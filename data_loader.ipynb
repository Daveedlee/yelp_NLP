{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding,LSTM,Dense,SpatialDropout1D, GlobalMaxPool1D, Dropout\n",
    "from keras.initializers import Constant\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import Adam\n",
    "from keras import optimizers\n",
    "import pickle\n",
    "from data_cleaner import overall_cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['business_id', 'cool_x', 'date', 'funny_x', 'review_id', 'stars_x',\n",
       "       'text', 'useful_x', 'user_id', 'average_stars', 'compliment_cool',\n",
       "       'compliment_cute', 'compliment_funny', 'compliment_hot',\n",
       "       'compliment_list', 'compliment_more', 'compliment_note',\n",
       "       'compliment_photos', 'compliment_plain', 'compliment_profile',\n",
       "       'compliment_writer', 'cool_y', 'elite', 'fans', 'friends', 'funny_y',\n",
       "       'name_x', 'review_count_x', 'useful_y', 'yelping_since', 'address',\n",
       "       'attributes', 'categories', 'city', 'hours', 'is_open', 'latitude',\n",
       "       'longitude', 'name_y', 'postal_code', 'review_count_y', 'stars_y',\n",
       "       'state'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_review = [json.loads(line) for line in open('datasets/review.json', 'r')]\n",
    "data_business = [json.loads(line) for line in open('datasets/business.json', 'r')]\n",
    "data_user = [json.loads(line) for line in open('datasets/user.json', 'r')]\n",
    "\n",
    "review_df = pd.DataFrame(data_review)\n",
    "biz_df = pd.DataFrame(data_business)\n",
    "user_df = pd.DataFrame(data_user)\n",
    "\n",
    "r_u_df = review_df.merge(user_df,on = \"user_id\")\n",
    "r_u_b_df = r_u_df.merge(biz_df, on = \"business_id\")\n",
    "r_u_b_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/pandas/core/frame.py:4117: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "review_text = overall_cleaner(r_u_b_df, ['text', 'user_id', 'state','stars_x'])\n",
    "review_text.set_index('user_id', inplace=True)\n",
    "\n",
    "states_l = []\n",
    "\n",
    "for i in np.unique(r_u_b_df['state']):\n",
    "    states_l.append(i)\n",
    "    \n",
    "nv_df = review_text.groupby('state').get_group('NV')\n",
    "nv_df.drop('state', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stars_x</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NV</th>\n",
       "      <td>2320491</td>\n",
       "      <td>2320491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>2082951</td>\n",
       "      <td>2082951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ON</th>\n",
       "      <td>784461</td>\n",
       "      <td>784461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NC</th>\n",
       "      <td>408060</td>\n",
       "      <td>408060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OH</th>\n",
       "      <td>321345</td>\n",
       "      <td>321345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PA</th>\n",
       "      <td>290097</td>\n",
       "      <td>290097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QC</th>\n",
       "      <td>179039</td>\n",
       "      <td>179039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WI</th>\n",
       "      <td>133660</td>\n",
       "      <td>133660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AB</th>\n",
       "      <td>99639</td>\n",
       "      <td>99639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IL</th>\n",
       "      <td>42371</td>\n",
       "      <td>42371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SC</th>\n",
       "      <td>21272</td>\n",
       "      <td>21272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TX</th>\n",
       "      <td>1071</td>\n",
       "      <td>1071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FL</th>\n",
       "      <td>726</td>\n",
       "      <td>726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NY</th>\n",
       "      <td>283</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>251</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WA</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CT</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VA</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGM</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NM</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GA</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NE</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NJ</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VT</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XWY</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DOW</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UT</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAS</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DUR</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TN</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CON</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BC</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGL</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          text  stars_x\n",
       "state                  \n",
       "NV     2320491  2320491\n",
       "AZ     2082951  2082951\n",
       "ON      784461   784461\n",
       "NC      408060   408060\n",
       "OH      321345   321345\n",
       "PA      290097   290097\n",
       "QC      179039   179039\n",
       "WI      133660   133660\n",
       "AB       99639    99639\n",
       "IL       42371    42371\n",
       "SC       21272    21272\n",
       "TX        1071     1071\n",
       "FL         726      726\n",
       "NY         283      283\n",
       "CA         251      251\n",
       "WA          19       19\n",
       "CT          17       17\n",
       "VA          16       16\n",
       "XGM         14       14\n",
       "NM          14       14\n",
       "GA          14       14\n",
       "NE          12       12\n",
       "AL          12       12\n",
       "NJ           8        8\n",
       "VT           8        8\n",
       "XWY          8        8\n",
       "AK           7        7\n",
       "AR           7        7\n",
       "DOW          4        4\n",
       "UT           4        4\n",
       "BAS          4        4\n",
       "DUR          3        3\n",
       "TN           3        3\n",
       "CON          3        3\n",
       "BC           3        3\n",
       "XGL          3        3"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_text.groupby('state').count().sort_values('text', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "nv_df = review_text.groupby('state').get_group('NV')\n",
    "az_df = review_text.groupby('state').get_group('AZ')\n",
    "nc_df = review_text.groupby('state').get_group('NC')\n",
    "on_df = review_text.groupby('state').get_group(\"ON\")\n",
    "oh_df = review_text.groupby('state').get_group('OH')\n",
    "pa_df = review_text.groupby('state').get_group('PA')\n",
    "qc_df = review_text.groupby(\"state\").get_group('QC')\n",
    "wi_df = review_text.groupby('state').get_group('WI')\n",
    "ab_df = review_text.groupby('state').get_group('AB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(nv_df.sample(n=95000), open('ten_sorted/nv_df.p', 'wb'))\n",
    "pickle.dump(az_df.sample(n=95000), open('ten_sorted/df_az.p', 'wb'))\n",
    "pickle.dump(nc_df.sample(n=95000), open('ten_sorted/df_nc.p', 'wb'))\n",
    "pickle.dump(on_df.sample(n=95000), open('ten_sorted/df_on.p', 'wb'))\n",
    "pickle.dump(oh_df.sample(n=95000), open('ten_sorted/df_oh.p', 'wb'))\n",
    "pickle.dump(pa_df.sample(n=95000), open('ten_sorted/df_pa.p', 'wb'))\n",
    "pickle.dump(qc_df.sample(n=95000), open('ten_sorted/df_qc.p', 'wb'))\n",
    "pickle.dump(wi_df.sample(n=95000), open('ten_sorted/df_wi.p', 'wb'))\n",
    "pickle.dump(ab_df.sample(n=95000), open('ten_sorted/df_ab.p', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
