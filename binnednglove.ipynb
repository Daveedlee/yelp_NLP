{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from yhelper import neural_modeling, overall_cleaner\n",
    "import pickle\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from keras.preprocessing import sequence, text\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, GlobalMaxPool1D, Dropout, Bidirectional, Conv1D, Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binned (Good vs Bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pickle.load(open('post_eda/eda_az.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df = overall_cleaner(df, ['text', 'review_rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df.review_rating.replace(1.0, False, inplace=True)\n",
    "text_df.review_rating.replace(2.0, False, inplace=True)\n",
    "text_df.review_rating.replace(3.0, False, inplace=True)\n",
    "text_df.review_rating.replace(4.0, True, inplace=True)\n",
    "text_df.review_rating.replace(5.0, True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>review_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5201838</td>\n",
       "      <td>i find this to be one of the better walmarts i...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>678826</td>\n",
       "      <td>best place ever very authentic staff super nic...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2683530</td>\n",
       "      <td>the bean and cheese burrito with green sauce i...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5802832</td>\n",
       "      <td>i guess to ups  oclock means  pm i tried to ma...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2197113</td>\n",
       "      <td>i am the vice president of product marketing f...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3750456</td>\n",
       "      <td>always looking for a great cup with knowledgea...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2781437</td>\n",
       "      <td>stopped in after mtb south mountain my boyfrie...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>302891</td>\n",
       "      <td>the food here is some of the best ive had in a...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3312023</td>\n",
       "      <td>loved the arizona roll but the spicy tuna roll...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4010842</td>\n",
       "      <td>pizza is always good at this location  want a ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94946 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text  review_rating\n",
       "5201838  i find this to be one of the better walmarts i...           True\n",
       "678826   best place ever very authentic staff super nic...           True\n",
       "2683530  the bean and cheese burrito with green sauce i...           True\n",
       "5802832  i guess to ups  oclock means  pm i tried to ma...          False\n",
       "2197113  i am the vice president of product marketing f...           True\n",
       "...                                                    ...            ...\n",
       "3750456  always looking for a great cup with knowledgea...          False\n",
       "2781437  stopped in after mtb south mountain my boyfrie...           True\n",
       "302891   the food here is some of the best ive had in a...           True\n",
       "3312023  loved the arizona roll but the spicy tuna roll...          False\n",
       "4010842  pizza is always good at this location  want a ...           True\n",
       "\n",
       "[94946 rows x 2 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_srs = text_df.text\n",
    "total_vocab = set(word for sentence in text_srs for word in sentence.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = text.Tokenizer(num_words=len(total_vocab))\n",
    "tokenizer.fit_on_texts(text_srs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_list = tokenizer.texts_to_sequences(text_srs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_seq = sequence.pad_sequences(tokenized_list, maxlen=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(padded_seq, pd.get_dummies(text_df.review_rating), test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0, ...,  1366,     4,    28],\n",
       "       [    0,     0,     0, ...,  8565,    16,    30],\n",
       "       [    0,     0,     0, ...,   344,     2,   510],\n",
       "       ...,\n",
       "       [    0,     0,     0, ...,     5,    89,    30],\n",
       "       [    0,     0,     0, ...,   133,    41,   495],\n",
       "       [    0,     0,     0, ...,    35, 35867,   372]], dtype=int32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94946, 2)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(text_df.review_rating).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, None, 150)         18442500  \n",
      "_________________________________________________________________\n",
      "bidirectional_5 (Bidirection (None, None, 128)         110080    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_5 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 18,552,838\n",
      "Trainable params: 18,552,838\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "embedding_size=150\n",
    "\n",
    "model.add(Embedding(len(total_vocab), embedding_size))\n",
    "model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 68360 samples, validate on 7596 samples\n",
      "Epoch 1/5\n",
      "68360/68360 [==============================] - 126s 2ms/step - loss: 0.5867 - acc: 0.6978 - val_loss: 0.4464 - val_acc: 0.7880\n",
      "Epoch 2/5\n",
      "68360/68360 [==============================] - 129s 2ms/step - loss: 0.2654 - acc: 0.8921 - val_loss: 0.2271 - val_acc: 0.9081\n",
      "Epoch 3/5\n",
      "68360/68360 [==============================] - 127s 2ms/step - loss: 0.1717 - acc: 0.9362 - val_loss: 0.2214 - val_acc: 0.9146\n",
      "Epoch 4/5\n",
      "68360/68360 [==============================] - 124s 2ms/step - loss: 0.1299 - acc: 0.9546 - val_loss: 0.2329 - val_acc: 0.9142\n",
      "Epoch 5/5\n",
      "68360/68360 [==============================] - 129s 2ms/step - loss: 0.0960 - acc: 0.9683 - val_loss: 0.2688 - val_acc: 0.9107\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa094914710>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=5, batch_size = 1500, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18990/18990 [==============================] - 15s 795us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.26795434442208027, 0.9058978409500986]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'acc']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_corpus_new(df):\n",
    "    corpus=[]\n",
    "    for review in tqdm(df['text']):\n",
    "        words=[word.lower() for word in word_tokenize(review)]\n",
    "        corpus.append(words)\n",
    "    return corpus   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94946/94946 [00:32<00:00, 2903.78it/s]\n"
     ]
    }
   ],
   "source": [
    "corpus = create_corpus_new(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dict={}\n",
    "with open('glove.6B.300d.txt','r') as f:\n",
    "    for line in f:\n",
    "        values=line.split()\n",
    "        word = values[0]\n",
    "        vectors=np.asarray(values[1:],'float64')\n",
    "        embedding_dict[word]=vectors\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN=150\n",
    "tokenizer_obj=Tokenizer()\n",
    "tokenizer_obj.fit_on_texts(corpus)\n",
    "sequences=tokenizer_obj.texts_to_sequences(corpus)\n",
    "\n",
    "glove_pad=pad_sequences(sequences,maxlen=MAX_LEN,truncating='post',padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words: 122780\n"
     ]
    }
   ],
   "source": [
    "word_index=tokenizer_obj.word_index\n",
    "print('Number of unique words:',len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122780/122780 [00:00<00:00, 671788.11it/s]\n"
     ]
    }
   ],
   "source": [
    "num_words=len(word_index)+1\n",
    "embedding_matrix=np.zeros((num_words,300))\n",
    "\n",
    "for word,i in tqdm(word_index.items()):\n",
    "    if i < num_words:\n",
    "        emb_vec=embedding_dict.get(word)\n",
    "        if emb_vec is not None:\n",
    "            embedding_matrix[i]=emb_vec           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94946, 150)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, None, 150)         22500000  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, None, 150)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, None, 128)         96128     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, None, 256)         263168    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_4 (Glob (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 22,860,581\n",
      "Trainable params: 22,860,581\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "embedding_size=150\n",
    "\n",
    "model.add(Embedding(150000, embedding_size))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(128,\n",
    "                 kernel_size=5,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 strides=1))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy', 'mse'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(glove_pad, pd.get_dummies(df.review_rating),test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 68360 samples, validate on 7596 samples\n",
      "Epoch 1/5\n",
      "68360/68360 [==============================] - 310s 5ms/step - loss: 1.2771 - acc: 0.5029 - mean_squared_error: 0.1280 - val_loss: 1.0823 - val_acc: 0.5943 - val_mean_squared_error: 0.1102\n",
      "Epoch 2/5\n",
      "68360/68360 [==============================] - 300s 4ms/step - loss: 0.9083 - acc: 0.6289 - mean_squared_error: 0.0959 - val_loss: 0.8094 - val_acc: 0.6643 - val_mean_squared_error: 0.0869\n",
      "Epoch 3/5\n",
      "68360/68360 [==============================] - 304s 4ms/step - loss: 0.7131 - acc: 0.7052 - mean_squared_error: 0.0781 - val_loss: 0.7596 - val_acc: 0.6892 - val_mean_squared_error: 0.0825\n",
      "Epoch 4/5\n",
      "68360/68360 [==============================] - 298s 4ms/step - loss: 0.6079 - acc: 0.7521 - mean_squared_error: 0.0675 - val_loss: 0.7666 - val_acc: 0.6836 - val_mean_squared_error: 0.0825\n",
      "Epoch 5/5\n",
      "68360/68360 [==============================] - 283s 4ms/step - loss: 0.5305 - acc: 0.7906 - mean_squared_error: 0.0590 - val_loss: 0.8130 - val_acc: 0.6781 - val_mean_squared_error: 0.0857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa0949358d0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=5, batch_size=1500, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18990/18990 [==============================] - 22s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8217614086820553, 0.6801474460179457, 0.08627992903969676]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'acc', 'mean_squared_error']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
